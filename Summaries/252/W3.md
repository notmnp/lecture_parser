# W3

## Study Notes

## Exam Study Notes – Signal Processing Fundamentals

### 1. Time Operations
| Operation | Continuous‑time | Discrete‑time |
|-----------|-----------------|---------------|
| **Shift** |  \(x(t\!-\!T) = \varphi(t)\)  → right shift if \(T>0\), left shift if \(T<0\). |  \(x[n\!-\!m] = \varphi[n]\)  → delay if \(m>0\), advance if \(m<0\). |
| **Scaling** |  Compress by factor \(a>1\): \(x(t)=\varphi(t/a)\) → \(g(t)=x(at)\).<br>Expand by \(a>1\): \(g(t)=x(t/a)\). |  Downsample by integer \(M\): \(x_d[n]=x[Mn]\).<br>Upsample by \(M\): insert \(M-1\) zeros between samples. |
| **Reversal** |  \(g(t)=x(-t)\). |  \(x_r[n]=x[-n]\). |

*Analogies:*  
- Shifting = sliding a tape.  
- Scaling = fast‑forward/rewind a video.  
- Reversal = playing a video backwards.

---

### 2. Basic Signals
| Signal | Definition | Key Properties |
|--------|------------|----------------|
| **Unit Step** \(u(t)\) | \(\displaystyle u(t)=\begin{cases}1,&t>0\\0,&t<0\end{cases}\) | Discontinuous at \(t=0\). Derivative → delta. |
| **Discrete Step** \(u[n]\) | \(\displaystyle u[n]=\begin{cases}1,&n>0\\0,&n<0\end{cases}\) | Same role in DT. |
| **Ramp** \(r(t)=t\) | Linear increase from 0. | Integral of step: \(r(t)=\int_{0}^{t}u(\tau)d\tau\). |
| **Dirac Delta** \(\delta(t)\) | \(\displaystyle \delta(t)=0\;(t\neq0),\;\int_{-\infty}^{\infty}\delta(t)\,dt=1\) | Sifting: \(\displaystyle\int_{-\infty}^{\infty}\phi(t)\delta(t-T)\,dt=\phi(T)\).<br>Multiplication: \(\phi(t)\delta(t)=\phi(0)\delta(t)\). |
| **Kronecker Delta** \(\delta[n]\) | \(\displaystyle \delta[n]=\begin{cases}1,&n=0\\0,&n\neq0\end{cases}\) | Discrete analog of \(\delta(t)\). |

---

### 3. Signal Properties
| Property | CT vs DT | Conditions |
|----------|----------|------------|
| **Analog / Digital** | Analog: infinite possible values. <br>Digital: finite set (e.g., \{-1,0,1\}). | |
| **Deterministic / Stochastic** | Deterministic: known equation/plot. | |
| **Causality** | **Causal**: \(x(t)=0\) for \(t<0\). <br>**Anti‑causal**: non‑zero only for \(t<0\). | |
| **Periodicity** | **Periodic**: repeats forever. <br>**Aperiodic**: no repeat. | |
| **Energy / Power** | **Energy signal**: finite \(E=\int_{-\infty}^{\infty}|x(t)|^2dt<\infty\).<br>**Power signal**: finite non‑zero average power.<br>**Neither**: does not satisfy either. | |

#### Energy & Power Formulas
| Signal | Energy | Power |
|--------|--------|-------|
| **CT** | \(E_x=\displaystyle\int_{-\infty}^{\infty}|x(t)|^2dt\) | \(P_x=\displaystyle\lim_{T\to\infty}\frac{1}{T}\int_{-T/2}^{T/2}|x(t)|^2dt\) |
| **DT** | \(E_x=\displaystyle\sum_{n=-\infty}^{\infty}|x[n]|^2\) | \(P_x=\displaystyle\lim_{N\to\infty}\frac{1}{2N+1}\sum_{n=-N}^{N}|x[n]|^2\) |

*Note:* Periodic signals always have infinite energy but finite power.

---

### 4. Power & RMS of Sinusoids
For a sinusoid \(x(t)=A\sin(\omega_0 t)\) or \(A\cos(\omega_0 t)\):

1. **Half‑angle identity**  
   \(\displaystyle \sin^2\theta=\frac{1-\cos2\theta}{2}\)  
   \(\displaystyle \cos^2\theta=\frac{1+\cos2\theta}{2}\)

2. **Power**  
   \[
   P_x=\frac{1}{T_0}\int_{0}^{T_0}A^2\sin^2(\omega_0 t)\,dt
   =A^2\frac{1}{2}= \frac{A^2}{2}
   \]

3. **RMS value**  
   \[
   \text{RMS}=\sqrt{P_x}=\frac{A}{\sqrt{2}}
   \]

*Quick check:* For \(A=1\) → RMS = \(1/\sqrt{2}\approx0.707\).

---

### 5. Common Transformations (Examples)
- **Time shift**: \(x(t-T)\) → delayed by \(T\) seconds.  
- **Scaling**: \(x(2t)\) → compressed (faster) by factor 2.  
- **Reversal**: \(x(-t)\) → mirror image across \(t=0\).  
- **Downsample DT**: \(x_d[n]=x[Mn]\) (lose samples).  
- **Upsample DT**: \(x_u[n] = \begin{cases}x[n/M],&n \text{ multiple of }M\\0,&\text{else}\end{cases}\).

---

### 6. Practical Tips
- **When in doubt about causality:** check if the signal is zero for \(t<0\).  
- **Power vs. Energy:** compute the integral/sum first; if it converges → energy; otherwise look at average power.  
- **Delta tricks:** use \(\delta(t-T)\) to "pick out" \(\phi(T)\).  
- **Step derivative:** \( \frac{du(t)}{dt}=\delta(t)\).  
- **Sinusoid RMS:** remember \( \frac{A}{\sqrt{2}}\); useful for converting peak to RMS in AC analysis.

---

> *These notes condense the core concepts needed for signal‑processing exams: time operations, elementary signals, signal properties, and power/RMS calculations.*

---

## Raw Slide Summaries

### Slide 1

The image presents a comprehensive lecture slide on "Useful Time Operations" in signal processing, dated September 16, 2025, at 11:10 AM. The slide is divided into sections, each addressing a specific operation.

**Learning Outcome:**
The learning outcome for this section is to perform basic time operations, including time shifting, time scaling, and time reversal.

**1st Operation: Time Shifting**

*   **Definition:** Time shifting involves delaying or advancing a signal in time.
*   **Continuous Time (C.T.) Section 1.2:** The operation is defined as:
    *   $x(t) = \varphi(t+T)$
    *   $x(t-T) = \varphi(t)$
*   **Explanation:** A time shift by $T$ is achieved by replacing $t$ with $t-T$.
*   **Conditions:**
    *   If $T>0$, it's a delay or right shifting.
    *   If $T<0$, it's an advance or left shifting.

**Discrete Time (D.T.) - Ch. 5.2:**

*   **Example:** Consider $x[n]$ and right shift $x[n]$ by 5 units (delayed):
    *   $x_s[n] = x[n-5]$
*   **Generalized Shifting:** Shifting by $m$ units:
    *   $x_s[n] = x[n-m]$
*   **Conditions:**
    *   If $m>0$, it's a delay or right shifting.
    *   If $m<0$, it's an advance or left shifting.

**2nd Operation: Time Scaling**

*   **Example:** Compress $x(t)$ by a factor of 2:
    *   Whatever happens in $x(t)$ at time $t$ happens at time $\frac{t}{2}$ in $g(t)$.
*   **Equations:**
    *   $x(t) = \varphi(\frac{t}{2})$
    *   $x(2t) = \varphi(t)$
*   **Generalized Compression:** If a signal $x(t)$ is compressed by a factor $a$ ($a>1$):

The slide features several graphs illustrating these concepts, including:

*   A graph showing $x(t)$ and its time-shifted version $g(t)$, with $g(t)$ being $x(t)$ shifted to the right by $T$.
*   A graph demonstrating the effect of time shifting on a discrete-time signal $x[n]$.
*   A graph illustrating the compression of a signal $x(t)$ by a factor of 2, resulting in $x(2t)$.

### Slide 2

The image presents a detailed lecture slide on signal processing, focusing on time scaling and its effects on continuous-time (C.T.) and discrete-time (D.T.) signals. The slide is densely packed with equations, formulas, definitions, bullet points, and a diagram illustrating the concepts.

**Equations and Formulas:**

*   $x(2t) = g(t)$
*   If a signal $x(t)$ is compressed by a factor $a$ ($a>1$), the compressed signal is $g(t) = x(at)$.
*   Compression in time is like speeding up the signal.
*   Expansion in time by a factor $a$ ($a>1$) $g(t)=x(\frac{t}{a})$.
*   Time scaling for D.T. signals (3.2) down sampling, upsampling and interpolation
*   Reminder: C.T. $g(t)=x(at) a>1$ Compression

**Consider $x[n]$ and compress/down sample by an integer factor $M$**

*   downsampled signal $x_d[n] = x[Mn]$ for $x[Mn]$ at $n=0,1,2,3,4$
*   $x_d[0]=x[M(0)]=x[0]$
*   $x_d[1]=x[M(1)]=x[M]$
*   $x_d[2]=x[M(2)]=x[2M]$

**Downsampling Causes information loss.**

**3rd operation: Time reversal**

*   C.T. Reflection of $x(t)$ about the vertical axis or to time reverse a signal, replace "$t$" with "-t"
*   $g(t)=x(-t)$

**Example:**

*   $\begin{cases} 
    x[n] & \text{for } n \in\{0,\pm1,\pm2,\pm3,...\} \\
    0 & \text{otherwise}
\end{cases}$

**Diagram:**

The diagram illustrates the effects of downsampling, upsampling, and interpolation on a signal. It consists of two main sections:

*   The left section shows the downsampling process, where a continuous signal $x(t)$ is sampled at regular intervals to produce a discrete-time signal $x[n]$. The downsampling process is represented by a factor of $2$, resulting in a new signal $x_d[n]$.
*   The right section demonstrates the upsampling process, where the downsampled signal $x_d[n]$ is upsampled by a factor of $2$ to produce a new signal $x_e[n]$. The upsampling process involves inserting zeros between the samples of $x_d[n]$.

The diagram also includes arrows and labels to illustrate the relationships between the different signals and the effects of downsampling and upsampling.

**Axes, Shapes, Arrows, Labels, Curves, Intersections:**

*   The diagram features two axes: the horizontal axis represents time ($n$), and the vertical axis represents the amplitude of the signal.
*   The diagram includes several curves and lines representing the original signal $x(t)$, the downsampled signal $x_d[n]$, and the upsampled signal $x_e[n]$.
*   Arrows are used to indicate the downsampling and upsampling processes, as well as the insertion of zeros during upsampling.
*   Labels are provided to identify the different signals and the effects of downsampling and upsampling.

Overall, the slide provides a comprehensive overview of time scaling and its effects on continuous-time and discrete-time signals, including downsampling, upsampling, and interpolation. The diagram effectively illustrates these concepts, making it easier for students to understand the relationships between the different signals and the effects of these operations.

### Slide 3

The image presents a detailed lecture slide focused on signal processing, specifically discussing time reversal of signals. The slide is divided into sections, each addressing different aspects of signal transformation.

**Example 1: Continuous-Time Signal Time Reversal**

*   The top-left corner features a graph with the title "Example!" in red text.
*   The graph displays a line with an arrow pointing upwards and to the right, labeled "t" on the x-axis and no label on the y-axis.
*   The function $x(-t) = 3(-t) = -3t$ is written above the graph, indicating a linear relationship where the slope is -3.
*   Adjacent to this graph is another graph showing $y(t) = x(-t)$, which appears to be a reflection of $x(t)$ across the y-axis.

**Time Reversal for Discrete-Time (D.T.) Signals**

*   Below the graphs, the equation for time reversal in discrete-time signals is provided: $x_r[n] = x[-n]$.
*   An example is given: $x[n] = 3n$ for $-4 \leq n \leq 6$.
*   To find $x[-n]$, the expression becomes $3(-n)$ for $-4 < (-n) \leq 6$.
*   This simplifies to $x[-n] = -3n$ for $4 \geq n \geq -6$ or $-6 \leq n \leq 4$.

**Key Takeaways**

*   The slide illustrates the concept of time reversal in both continuous and discrete-time signals.
*   For continuous-time signals, the transformation involves replacing $t$ with $-t$.
*   For discrete-time signals, time reversal is achieved by replacing $n$ with $-n$.

In summary, the lecture slide provides a comprehensive overview of time reversal in signal processing, covering both continuous and discrete-time signals with examples and graphical representations.

### Slide 4

The image presents a detailed lecture slide on "Some useful signals Part 1," dated September 18, 2025, at 11:00 AM. The slide is divided into sections, each focusing on a specific type of signal.

**Learning Outcome**
The learning outcome for this section, which spans this week and next week, is to become familiar with three basic signals: step, impulse, and complex exponentials, and to perform time operations on them.

**Unit Step (Oliver Heaviside)**
The unit step function, denoted as $u(t)$, is defined as:

* $u(t) = \begin{cases} 1 & t > 0 \\ 0 & t < 0 \end{cases}$

A graph of $u(t)$ is provided, showing a horizontal line at $y=0$ for $t<0$ and a horizontal line at $y=1$ for $t>0$.

**Discrete-Time Unit Step**
The discrete-time unit step function, denoted as $u[n]$, is defined as:

* $u[n] = \begin{cases} 1 & n > 0 \\ 0 & n < 0 \end{cases}$

A graph of $u[n]$ is shown, with vertical lines at integer values of $n$, where $u[n]=1$ for $n>0$ and $u[n]=0$ for $n<0$.

**Examples**
Several examples are provided to illustrate the application of the unit step function:

* $x(t) = u(t-2) - u(t-4)$, which represents a rectangular pulse.
* $u(t-2)$ and $u(t-4)$ are graphed, showing step functions shifted to the right by 2 and 4 units, respectively.
* $-u(t-4)$ is graphed, showing a step function shifted to the right by 4 units and reflected about the x-axis.

**Ramp Function**
The ramp function, denoted as $r(t)$, is defined as:

* $r(t) = t$

A graph of $r(t)$ is provided, showing a straight line with a slope of 1.

**Example**
An example is given, where $x(t) = r(t)[u(t)-u(t-2)] = t[u(t)-u(t-2)]$.

**Unit Impulse**
The unit impulse function is mentioned, but not fully defined or graphed on this slide.

Overall, the slide provides a comprehensive introduction to the unit step function, its discrete-time counterpart, and the ramp function, along with examples and graphs to illustrate their properties and applications.

### Slide 5

The image presents a comprehensive overview of the unit impulse function, also known as the Dirac delta function. The content is organized into sections, each focusing on a specific aspect of the unit impulse.

**Unit Impulse Function**

*   **Definition and Properties**
    *   The Dirac delta function is defined as:
        *   $\delta(t) = 0$ for $t \neq 0$
        *   $\int_{-\infty}^{\infty} \delta(t) dt = 1$
    *   A graphical representation of the Dirac delta function is provided, showing it as a tall and narrow rectangle with an area of one.
    *   The definition of an impulse is given as a rectangular pulse with:
        *   Infinitesimally small width (duration) $\epsilon \rightarrow 0$
        *   Infinitely large height $\frac{1}{\epsilon} \rightarrow \infty$
        *   Overall area is unity
*   **Kronecker Delta Function**
    *   The Kronecker delta function is defined as:
        *   $\delta[n] = \begin{cases} 1 & n=0 \\ 0 & n \neq 0 \end{cases}$

**Properties of the Impulse Signal**

*   **Multiplication by an Impulse**
    *   The property of multiplication by an impulse is stated as:
        *   $\phi(t) \delta(t) = \phi(0) \delta(t)$
    *   More generally, for an impulse shifted to time $T$:
        *   $\phi(t) \delta(t-T) = \phi(T) \delta(t-T)$
*   **Sampling or Sifting Property of an Impulse**
    *   The sampling or sifting property of an impulse is expressed as:
        *   $\int_{-\infty}^{\infty} \phi(t) \delta(t-T) dt = \int_{-\infty}^{\infty} \phi(T) \delta(t-T) dt = \phi(T) \int_{-\infty}^{\infty} \delta(t-T) dt = \phi(T)$

**Key Points**

*   The unit impulse function has zero value everywhere except at $t=0$, where it is infinite.
*   The area under the unit impulse function is equal to one.
*   The Kronecker delta function is a discrete-time counterpart of the Dirac delta function.
*   The multiplication property of the impulse signal states that multiplying a function by an impulse results in the function evaluated at the impulse location times the impulse.
*   The sampling or sifting property of an impulse allows for the extraction of the value of a function at a specific point using the impulse.

Overall, the image provides a detailed explanation of the unit impulse function, its properties, and its applications in signal processing.

### Slide 6

The image presents a comprehensive lecture slide on the Dirac delta function, its properties, and its relationship with the step signal. The slide is divided into several sections, each addressing a specific aspect of the Dirac delta function.

**Dirac Delta Function Definition**

* The Dirac delta function is defined as:
  $\int_{-\infty}^{\infty} \phi(t)\delta(t-T) dt = \phi(T)$
* The area under the multiplication of the function and an impulse shifted to time "T" gives the value of the function at time T.
* This can also be interpreted as sampling the function at time T.

**Connection to Strobe Dancer Example**

* A graph illustrates the connection to the strobe dancer example:
	+ A black line represents a function $\phi(t)$ over time $t$.
	+ A series of red arrows represent a pulse train or strobe light over time $t$.
	+ The yellow box highlights the relationship between the function and the pulse train.

**Relationship with Step Signal**

* The relationship between the Dirac delta function and the step signal $u(t)$ is discussed:
	+ The derivative of the step signal $u(t)$ is equal to the Dirac delta function $\delta(t)$: $\frac{du(t)}{dt} = \delta(t)$.
	+ The integral of the Dirac delta function from $t_0$ to $t_1$ is equal to $u(t_1) - u(t_0)$.
	+ The integral of the Dirac delta function from $-\infty$ to $\infty$ is equal to $1$.

**Example**

* A simple example is provided:
	+ A sequence $x[n]$ is represented by a series of vertical arrows.

**Key Takeaways**

* The Dirac delta function is a fundamental concept in signal processing and analysis.
* It is used to sample functions and represent impulses in time.
* The Dirac delta function is closely related to the step signal, and its derivative is equal to the Dirac delta function.

Overall, the lecture slide provides a detailed explanation of the Dirac delta function, its properties, and its applications in signal processing.

### Slide 7

The image presents a lecture slide focused on signal processing, specifically addressing discrete-time signals represented in two different forms: as a sum of Dirac delta functions and as a combination of a Dirac delta function and a unit step function.

### **Equations and Formulations**

The slide provides two equivalent representations of the same signal $x[n]$:

1. **Sum of Dirac Delta Functions:**
   \[ x[n] = \delta[n-1] + 2\delta[n-2] + 3\delta[n-3] + 3\delta[n-4] + 3\delta[n-5] \]

2. **Combination of Dirac Delta and Unit Step Functions:**
   \[ x[n] = \delta[n-1] + 2\delta[n-2] + 3u[n-3] - 3u[n-6] \]

### **Graphical Representation**

The slide includes a graph with the title "Example!" in red text at the top left corner. The graph displays a discrete-time signal $x[n]$ with the following characteristics:

- The x-axis is labeled "$n$" and ranges from 0 to 7.
- The y-axis is not explicitly labeled but represents the amplitude of the signal.
- The graph features five vertical lines (stem plot) at $n = 1, 2, 3, 4,$ and $5$, with amplitudes of $1, 2, 3, 3,$ and $3$ respectively. These lines are colored red, except for the ones at $n=1$ and $n=2$, which are highlighted with yellow and light blue vertical bars, respectively.

### **Additional Details**

- The background of the slide resembles graph paper, aiding in the visualization and plotting of signals.
- At the bottom of the slide, it is indicated that this is "Week 3 Page 4," suggesting it is part of a series of lecture notes or slides for a course on signal processing or a related field.

### **Conclusion**

In summary, the slide provides a detailed example of representing a discrete-time signal in two mathematical forms and visually illustrates the signal using a stem plot. This example likely serves to help students understand how different mathematical representations can describe the same signal and how these representations can be graphically interpreted.

### Slide 8

## Tutorial: Signal Properties
Tuesday, September 16, 2025  10:18 AM

## Quick Review - Signal Properties

### Signal Types
- **Continuous Time (CT)**: has value for all values of t
- **Discrete Time (DT)**: has value only at discrete (integer) values of time (n)

### Analog vs. Digital
- **Analog ≠ Digital** refer to the value of the signal itself, not time
- **Analog ≠ CT/DT**

### Signal Characteristics
- **Deterministic**: being defined by an equation or a plot
- **Stochastic**: random

### Causality
- **Causal**: ≠0 only when t ≥ 0
- **Non-causal**: ≠0 when t ≥ 0 and t < 0
- **Anti-causal**: ≠0 only when t < 0

### Periodicity
- **Periodic**: repeats infinitely
- **Aperiodic**: doesn’t repeat forever

### Energy and Power
- **Energy**: A signal with finite energy (Energy Signal)
- **Power**: A power signal has finite non-zero power
- **Neither**: Doesn’t meet either of above criteria

### Formulas
#### Continuous Time
- **Total Energy of Signal**: $E_x = \int_{-\infty}^{\infty} |x(t)|^2 dt$
- **Average Power of Signal**: $P_x = \lim_{T \to \infty} \frac{1}{T} \int_{-T/2}^{T/2} |x(t)|^2 dt$

#### Discrete Time
- **Total Energy of Signal**: $E_x = \sum_{n=-\infty}^{\infty} |x[n]|^2$
- **Average Power of Signal**: $P_x = \lim_{N \to \infty} \frac{1}{2N + 1} \sum_{n=-N}^{N} |x[n]|^2$

### Example 1: Classify the signal given below according to the above properties
- **Signal**: $x[n] = \sin(\frac{\pi}{2} \cdot n) = -1, 0, 1$

The graph shows a discrete-time signal with values at $n = ...,-5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5$ with a sinusoidal pattern labeled. The values are marked as follows: 
- At $n=-5$, the value is 1.
- At $n=-4$, the value is 0.
- At $n=-3$, the value is -1.
- At $n=-2$, the value is 0.
- At $n=-1$, the value is 1.
- At $n=0$, the value is 0.
- At $n=1$, the value is -1.
- At $n=2$, the value is 0.
- At $n=3$, the value is 1.
- At $n=4$, the value is 0.
- At $n=5$, the value is -1.

There are red arrows indicating a repeating pattern every four units. The handwritten note next to the graph reads: "1: CT/DT: Discrete-Time ... has value at ...  ...".

### Slide 9

The image presents a detailed lecture slide on signal processing, covering various aspects of signals. The content is organized into sections, each addressing a specific property or characteristic of signals.

**Signal Properties**

*   **2: Analog/Digital**: This section highlights that possible values of a signal can be -1, 0, or 1, and notes that there are only three digital signals.
*   **3: Deterministic/Stochastic**: It defines deterministic signals as those for which we have an expression.
*   **4: Causality**: A signal \(x[n]\) is considered non-zero both when \(n \geq 0\) and \(n < 0\), implying it is non-causal.
*   **5: Periodicity**: A signal is periodic if it repeats forever, with an example given where a signal repeats every 4 samples, making its period = 4.

**Energy/Power/Neither**

*   For periodic signals, the energy \(E_x\) is given by \(E_x = \sum_{n=-\infty}^{\infty} |x[n]|^2\), which is always positive and equals infinity (\(E_x = \infty\)).
*   It is noted that periodic signals are always power signals.

**Definitions**

*   **Energy**: Measures the size of a signal.
*   **Power**: The time-average of energy, defined as \(P_x = \lim_{T \to \infty} \frac{1}{T} E_x\).

**Example 2**

*   The example provides a signal \(x(t) = \begin{cases} 0 & t < 0 \\ e^{-t} & t \geq 0 \end{cases}\) and asks to plot the signal, then determine if it is an energy signal, power signal, or neither.
*   The energy \(E_x\) of the signal is calculated as \(E_x = \int_{-\infty}^{\infty} |x(t)|^2 dt = \int_{0}^{\infty} |e^{-t}|^2 dt = \int_{0}^{\infty} e^{-2t} dt = \left[ -\frac{1}{2} e^{-2t} \right]_{0}^{\infty} = \frac{1}{2}\).
*   The conclusion is that the signal has finite energy, making it an energy signal.

In summary, the lecture slide covers fundamental properties of signals, including analog/digital, deterministic/stochastic, causality, periodicity, and energy/power characteristics. It provides definitions and an example to illustrate how to classify a signal based on its energy.

### Slide 10

The image presents a detailed lecture slide focused on signal processing, specifically addressing the power and RMS (Root Mean Square) of continuous-time sinusoids. The slide is densely packed with mathematical equations, formulas, and explanations, indicating a comprehensive coverage of the topic.

**Key Points:**

* **Half Angle Identities:**
  - $\sin^2 \theta = \frac{1 - \cos(2\theta)}{2}$
  - $\cos^2 \theta = \frac{1 + \cos(2\theta)}{2}$

* **Power of a Continuous-Time Sinusoid:**
  - The power $P_x$ of a signal $x(t)$ is given by $P_x = \lim_{T \to \infty} \frac{1}{T} \int_{-T/2}^{T/2} |x(t)|^2 dt$
  - For a sinusoid $x(t) = A \sin(\omega_0 t)$, the power can be calculated using the half-angle identity.

* **Shortcut for Periodic Signals:**
  - For periodic signals, the power can be found by integrating over one period $T_0$: $P_x = \frac{1}{T_0} \int_{T_0} |x(t)|^2 dt$
  - Applying this to $x(t) = A \sin(\omega_0 t)$ yields $P_x = \frac{1}{T_0} \int_{T_0} A^2 \sin^2(\omega_0 t) dt$

* **Derivation of Power for Sinusoids:**
  - Using the half-angle identity, $\sin^2(\omega_0 t) = \frac{1 - \cos(2\omega_0 t)}{2}$
  - Substituting into the power equation gives $P_x = A^2 \frac{1}{T_0} \int_{T_0} \frac{1 - \cos(2\omega_0 t)}{2} dt$
  - This simplifies to $P_x = \frac{A^2}{2}$ for any sinusoid (cosine or sine).

* **RMS of a Sinusoid:**
  - The RMS value is given by $RMS = \sqrt{P_x} = \sqrt{\frac{A^2}{2}} = \frac{A}{\sqrt{2}}$

* **Example 4: Complex Exponential Signal**
  - The power of $x(t) = e^{at} \cos(\omega_0 t)$ is to be found.
  - The approach involves directly applying the power formula: $P_x = \lim_{T \to \infty} \frac{1}{T} \int_{-T/2}^{T/2} |e^{at} \cos(\omega_0 t)|^2 dt$

**Summary:**

The lecture slide provides a thorough analysis of the power and RMS of continuous-time sinusoids, leveraging half-angle identities and properties of periodic signals. It derives that the power of a sinusoid $A \sin(\omega_0 t)$ or $A \cos(\omega_0 t)$ is $\frac{A^2}{2}$, and the RMS value is $\frac{A}{\sqrt{2}}$. Additionally, it introduces an example involving a complex exponential signal, setting the stage for further analysis.

### Slide 11

The image presents a mathematical derivation, likely from a lecture on signal processing or a related field. The content is written in black and red ink on a white background.

**Equations and Derivations:**

The derivation begins with:

\[= \lim_{T \to \infty} \frac{1}{T} \int_{-T/2}^{T/2} e^{jat} e^{-jat} \cos^2(\omega_0 t) dt\]

\[= e^{0} = 1\]

This simplifies to:

\[= \lim_{T \to \infty} \frac{1}{T} \int_{-T/2}^{T/2} \cos^2(\omega_0 t) dt\]

\[= \lim_{T \to \infty} \frac{1}{T} \int_{-T/2}^{T/2} |\cos(\omega_0 t)|^2 dt\]

A note in red ink states:

"note this is identical to power of $\cos(\omega_0t)$"

The derivation then concludes with:

\[=> P_x = \frac{A^2}{2} = \frac{I^2}{2} = \frac{1}{2} => RMS = \sqrt{P_x} = \frac{1}{\sqrt{2}}\]

**Key Points:**

* The derivation involves limits and integrals of trigonometric functions.
* The power of a cosine function is identified.
* The final result relates to the power and RMS (Root Mean Square) of a signal.

**Visuals:**

There are no diagrams or images on the slide, only handwritten mathematical expressions.

